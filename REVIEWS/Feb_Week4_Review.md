

### Energy aware resource scheduling in FoG environment for IoT-Based applications

- The traditional cloud computing architecture is unable to handle the latency-sensitive
applications efficiently hence the FoG architecture has been widely implemented with IoT devices to efficiently
retrieve or forward the data. 

- As the number of IoT devices increase exponentially, the amount of data is increases resulting in the growing energy
demand. The energy consumption prediction and optimization is an area of interest. There is a requirement for an efficient
mechanism to store, process, and retrieve data as the connected objects use different energy utilization strategies.

-  Cloud computing architecture due to increase in the number of IoT devices and their processing needs, the cloud computing
architecture is unable to provide real-time response to latency-sensitive applications. Various caching schemes have been suggested for the
IP-based and emerging internet architectures such as content-centric networks. 

- The heterogeneity and availability of resources have generated the need of efficient utilization of resources for sustainable smart cities.
- Cisco's FoG computing seeks to resolve the limitations of cloud architecture. The FoG architecture is the distributed network to provide speedy
services amid the cloud and geographically distributed end user devices to bid computation offloading prospects such as latency, bandwidth, and energy
consumption.
- FoG computing uses FoG nodes which is a set of heterogeneous and distributed resources with moderate storage and processing capabilities. It is a proven
efficient architecture to handle the requirements of latency-sensitive applications with minimal bandwidth and energy requirements. The FoG architecture has 
three layers: IoT devices and sensors, network layer, cloud servers. 
- In a FoG environment, any intermediary node with computational and storage capabilities can act as a FoG node. The limitation and heterogeneity of resources
have made it a challenging task for resource allocation and provisioning in the FoG layer. 
- The taxonomy of FoG computing:
	- Resource scheduling
	- Task offloading
	- Application management
	- Resource allocation
	- Task scheduling
	- Security
	
- Many smart IoT applications need to handle dynamic resource management and efficient utilization for a sustainable environment. 
- All sensitive applications in terms of location, bandwidth, time consumption are handled by the FoG computing for IoE.
- The system should be capable enough of detecting and handling those issues which can further lead to change in user requirements. In case of any kind of failure
can lead to delay in reaching the destination which can further result in loss and damages. Due to the dynamic nature of user, management of resources dynamically 
with energy conservation schemes is the need of the hour. 
- QoS parameters:
	- Throughput
	- Deadline
	- Response utilization
	- Cost
	- Execution time
	- Response time
	- Energy consumption
	- Security
	- Availability
	- Scalability

- FoG computing performs data analysis on local network with a control response while Edge Computing does large volume real time data processing via applications.
- Erlang is a unit used to measure traffic density in telecommunication systems
- Research gap:
	- Dynamic randomness in actual scheduling, fuzzy delivery data, uncertain processing time and emergency order need to be processed. Various schemes need to be
	improved.
	
	- Which algorithms, techniques, parameters and pricing schemes are being used for energy harvesting in smart energy systems:
		- Energy resource scheduling algorithms
			- PSO
			- Genetic algorithms
			- MILP 
			- DMES
	
	- These algorithms focus on energy saving and cost reduction. 
	- The parameters of energy optimization are:
		- Future energy prediction (FEP)
		- Energy optimization (EO)
		- Real-time pricing (RTP)
		- Reduce power consumption (RPC)
		- Reduced cost (RC)
		



#### A Deadline-aware dynamic service placement algorithm for workflow-oriented IoT applicants in Fog-Cloud computing environments

- Develops a comprehensive framework that supports QoS-aware service placement in a fog computing environment. A novel multitier fog 
computing architecture called DoSP provides the services both in fog and cloud nodes. 
The research methodology - Utilizes low-cost fog resources while ensuring that the response time satisfies a given time constraint. 
GA used to dynamically determine the service placement in the fog environment. 

- Cloud computing servers are located in a remote place and provide computing resources on demand. It encounters QoS inefficiencies such 
high latency, high bandwidth and energy consumption making it less ideal for IoT applications. Fog computing solves these hurdles as an 
elongated version of cloud computing with effective network bandwidth utilization, heterogeneous computation, workload distribution and mobility.

- Workflow based IoT applications in the real-world need to desire latency where the edge of the network with storage and computing services play a 
crucial role. Placement of IoT applications with proper utilization of cloud and fog computing resources is a game-changing approach that will have a 
huge impact on the deployed applications. 

- Edge management services perform probing, monitoring, alarming, and storing. The edge management services work on top of virtual clusters to support 
edge computing applications. 
	
